![Accuracy](screenshot/CNNss.PNG)

Rapport du Projet : Classification des √âmotions avec un R√©seau de Neurones Convolutif (CNN)
1. Introduction
L‚Äôobjectif de ce projet est de construire un mod√®le capable de reconna√Ætre diff√©rentes √©motions humaines √† partir d‚Äôimages. Pour cela, nous utilisons un r√©seau de neurones convolutif (CNN), un type de mod√®le particuli√®rement adapt√© √† l‚Äôanalyse d‚Äôimages.
Le dataset utilis√© contient des images de visages class√©es selon 7 √©motions diff√©rentes. Le code mis en place permet de pr√©parer les donn√©es, visualiser des exemples, construire le mod√®le, l‚Äôentra√Æner, l‚Äô√©valuer et tester les pr√©dictions finales.
________________________________________
2. Chargement du Dataset
Le dataset se trouve dans le r√©pertoire :
C:\Users\chhou\PycharmProjects\PythonProject3\emotions
Les images sont organis√©es en sous-dossiers, un dossier par √©motion.
Le code utilise image_dataset_from_directory() pour cr√©er automatiquement un dataset avec :
‚Ä¢	Un dataset d'entra√Ænement (80%)
‚Ä¢	Un dataset de validation (20%)
‚Ä¢	Un dataset complet (reshuffl√©) permettant de cr√©er un dataset de test (15%)
train_dataset = tf.keras.utils.image_dataset_from_directory(..., validation_split=0.2, subset="training")
validation_dataset = tf.keras.utils.image_dataset_from_directory(..., validation_split=0.2, subset="validation")
full_dataset = tf.keras.utils.image_dataset_from_directory(...)
Les images sont redimensionn√©es √† 48√ó48 pixels avec un batch size de 32.
________________________________________
3. Visualisation des Donn√©es
Avant l'entra√Ænement, un √©chantillon d‚Äôimages est affich√© :
‚Ä¢	9 images sont montr√©es
‚Ä¢	Chaque image montre un visage annot√© avec son √©motion r√©elle
Cela permet d‚Äôavoir un aper√ßu du dataset et de v√©rifier que l‚Äôimportation est correcte.
plt.imshow(images[i].numpy().astype("uint8"))
plt.title(class_names[labels[i]])
________________________________________
4. Conception du Mod√®le CNN
Le mod√®le construit suit une architecture classique compos√©e de :
üîπ 1. Normalisation :
tf.keras.layers.Rescaling(1./255)
Pour mettre les valeurs de pixels entre 0 et 1.
üîπ 2. Trois blocs Convolution + MaxPooling :
‚Ä¢	Conv2D(32 filtres) ‚Üí extraction de caract√©ristiques simples (bords, textures)
‚Ä¢	Conv2D(64 filtres) ‚Üí extraction interm√©diaire
‚Ä¢	Conv2D(128 filtres) ‚Üí extraction de caract√©ristiques plus complexes
‚Ä¢	Apr√®s chaque convolution, une couche MaxPooling2D r√©duit la dimension.
üîπ 3. Couches Fully Connected :
‚Ä¢	Flatten() aplati les cartes de features
‚Ä¢	Dense(128, relu) ‚Üí r√©seau dense interm√©diaire
‚Ä¢	Dense(7, softmax) ‚Üí sortie √† 7 classes (une par √©motion)
Cette architecture balance bien simplicit√© et performance.
________________________________________
5. Compilation et Entra√Ænement
Le mod√®le est compil√© avec :
‚Ä¢	Optimiseur : Adam
‚Ä¢	Loss : sparse_categorical_crossentropy
‚Ä¢	M√©trique : accuracy
Puis entra√Æn√© pendant 30 √©poques :
modelCNN.fit(train_dataset, epochs=30, validation_data=validation_dataset)
Cela permet de :
‚Ä¢	Surveiller la pr√©cision d‚Äôentra√Ænement
‚Ä¢	V√©rifier la g√©n√©ralisation via la validation
________________________________________
6. √âvaluation du Mod√®le
Le dataset de test extrait du dataset complet est utilis√© :
modelCNN.evaluate(test_dataset, verbose=2)
Cette √©tape permet d‚Äôobtenir une mesure objective des performances du mod√®le sur des images jamais vues.
________________________________________
7. Pr√©dictions Finales
Le mod√®le r√©alise ensuite des pr√©dictions sur un batch du dataset de test :
‚Ä¢	On applique le mod√®le pour obtenir un vecteur de probabilit√©s
‚Ä¢	On prend la classe avec argmax
‚Ä¢	On affiche pour chaque image :
Vrai: <classe r√©elle> ‚Äî Pr√©dit: <classe pr√©dite>
Cela permet de v√©rifier la qualit√© des pr√©dictions et d‚Äôidentifier les √©ventuelles confusions.

