![Accuracy](screenshot/CNNss.PNG)

Rapport du Projet : Classification des √âmotions avec un R√©seau de Neurones Convolutif (CNN)
1. Introduction

L‚Äôobjectif de ce projet est de construire un mod√®le capable de reconna√Ætre diff√©rentes √©motions humaines √† partir d‚Äôimages.
Pour cela, nous utilisons un r√©seau de neurones convolutif (CNN), un type de mod√®le particuli√®rement adapt√© √† l‚Äôanalyse d‚Äôimages.

Le dataset contient des images de visages organis√©es en 7 √©motions.
Le code permet de :

Pr√©parer les donn√©es

Visualiser des images

Construire un mod√®le CNN

L‚Äôentra√Æner et le valider

L‚Äô√©valuer

Tester les pr√©dictions finales

2. Chargement du Dataset

Le dataset se trouve dans :

C:\Users\chhou\PycharmProjects\PythonProject3\emotions


Les images sont organis√©es par √©motion (un dossier = une √©motion).

Le chargement utilise image_dataset_from_directory() :

train_dataset = tf.keras.utils.image_dataset_from_directory(..., validation_split=0.2, subset="training")
validation_dataset = tf.keras.utils.image_dataset_from_directory(..., validation_split=0.2, subset="validation")
full_dataset = tf.keras.utils.image_dataset_from_directory(...)


80% ‚Üí entra√Ænement

20% ‚Üí validation

15% des donn√©es reshuffl√©es ‚Üí test

Les images sont redimensionn√©es en 48√ó48 pixels, batch size = 32.

3. Visualisation des Donn√©es

Avant l‚Äôentra√Ænement, un √©chantillon de 9 images est affich√© :

Chaque image montre un visage

Avec l'√©motion r√©elle en titre

plt.imshow(images[i].numpy().astype("uint8"))
plt.title(class_names[labels[i]])


Cela confirme que le chargement du dataset est correct.

4. Conception du Mod√®le CNN

Le mod√®le est compos√© de plusieurs blocs :

üîπ 1. Normalisation
tf.keras.layers.Rescaling(1./255)

üîπ 2. Convolutions + MaxPooling

Conv2D(32) : extraction de caract√©ristiques simples

Conv2D(64) : extraction interm√©diaire

Conv2D(128) : extraction avanc√©e

MaxPooling2D() entre chaque convolution

üîπ 3. Couches Denses

Flatten()

Dense(128, relu)

Dense(7, softmax) : 7 classes d‚Äô√©motions

Architecture simple et efficace pour des images 48√ó48.

5. Compilation et Entra√Ænement

Le mod√®le est compil√© avec :

Optimiseur : Adam

Loss : sparse_categorical_crossentropy

Metric : accuracy

Entra√Ænement sur 30 epochs :

modelCNN.fit(train_dataset, epochs=30, validation_data=validation_dataset)


Suivi :

pr√©cision d‚Äôentra√Ænement

pr√©cision de validation

6. √âvaluation

Le mod√®le est √©valu√© sur le dataset de test :

modelCNN.evaluate(test_dataset, verbose=2)


Ce test mesure les performances r√©elles du mod√®le sur des images jamais vues.

7. Pr√©dictions Finales

Le mod√®le effectue des pr√©dictions :

Probabilit√©s g√©n√©r√©es par model.predict

Classe pr√©dite = argmax

Affichage sous la forme :

Vrai: <classe r√©elle> ‚Äî Pr√©dit: <classe pr√©dite>


Cela permet de d√©tecter les erreurs ou confusions entre √©motions.
